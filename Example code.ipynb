{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glymur\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.measure import compare_ssim as ssim\n",
    "import random\n",
    "\n",
    "%run -i 'dataset_models.py'\n",
    "%run -i 'new_utilities.py'\n",
    "%run -i 'train_nn.py'\n",
    "%run -i 'nn_models.py'\n",
    "%run -i 'collect_data.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting data first. There are helper functions for CIFAR-10, MNIST, Faces, FSDD datasets. For a custom dataset, each row must be a data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '' #Specify data directory\n",
    "train_data, train_labels, test_data, test_labels = collect_data_cifar10(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run accuracy experiments, we divide the training data into two parts. One to train for the compression algorithm and the other to train for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_alg, train_data_acc, train_labels_acc = split_train_test(train_data, train_labels, split=0.6)\n",
    "test_data_alg = np.concatenate((train_data_acc,test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset object and metrics objects for each algorithm. You can either pass the entire dataset and specify the fraction of training data, or pass the train and test dataset separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_10_dataset = Dataset(np.array([train_data_alg,test_data_alg]))\n",
    "metrics_pca = Metrics(accuracy=1)\n",
    "metrics_pba = Metrics(accuracy=1)\n",
    "metrics_jpeg = Metrics(accuracy=1)\n",
    "metrics_jpeg2k = Metrics(accuracy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following cells contain code to obtain rate-distortion points for PCA, PBA, JPEG, JPEG2000 where distortion metrics are SNR, SSIM or classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCA\n",
    "num_comp_l = np.concatenate((np.array([3,5]),\n",
    "                             (np.logspace(1,np.log10(cifar_10_dataset.num_tr/2),num=5, endpoint=False)).astype(np.uint16),\n",
    "                             (np.logspace(np.log10(cifar_10_dataset.num_tr/2),np.log10(cifar_10_dataset.num_tr),num=10)).astype(np.uint16))) \n",
    "for num_components in num_comp_l:\n",
    "    cifar_10_dataset = quant_pca(cifar_10_dataset,num_components,a=900)\n",
    "    metrics_pca = compute_snr_ssim_metrics(cifar_10_dataset,metrics_pca,algorithm='pca',multichannel=True)\n",
    "    metrics_pca = cifar_compute_accuracy(cifar_10_dataset,train_labels_acc,test_labels,metrics_pca,'pca',epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PBA\n",
    "a=900\n",
    "lmb_vec = np.logspace(np.log2(np.min(cifar_10_dataset.pca_eigval/(8*(a-1)))),np.log2(np.max(cifar_10_dataset.pca_eigval/(4*(a-1))) - 1),base=2,num=30)\n",
    "for lmb in lmb_vec:\n",
    "    cifar_10_dataset = quant_pba(cifar_10_dataset,lmb,a)\n",
    "    metrics_pba = compute_snr_ssim_metrics(cifar_10_dataset,metrics_pba,algorithm='pba',multichannel=True)\n",
    "    metrics_pba = cifar_compute_accuracy(cifar_10_dataset,train_labels_acc,test_labels,metrics_jpeg,'pba',epochs=2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JPEG\n",
    "for qual in range(1,101,4):\n",
    "    cifar_10_dataset,metrics_jpeg = quant_jpegfamily(cifar_10_dataset,metrics_jpeg,qual,multichannel=True)\n",
    "    metrics_jpeg = cifar_compute_accuracy(cifar_10_dataset,train_labels_acc,test_labels,metrics_pba,'jpeg',epochs=2) \n",
    "#JPEG2000    \n",
    "cratio = [1,2,3,5,8,10,13,15,20,30,50,75,100,1000]\n",
    "for ratio in cratio:\n",
    "    cifar_10_dataset,metrics_jpeg2k = quant_jpegfamily(cifar_10_dataset,metrics_jpeg2k,ratio,multichannel=True)\n",
    "    metrics_jpeg2k = cifar_compute_accuracy(cifar_10_dataset,train_labels_acc,test_labels,metrics_jpeg2k,'jpeg2k',epochs=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
